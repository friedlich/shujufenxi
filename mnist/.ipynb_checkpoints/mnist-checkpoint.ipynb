{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# settings\n",
    "LEARNING_RATE = 1e-4\n",
    "# set to 20000 on local environment to get 0.99 accuracy\n",
    "# 在本地环境上设置为20000可获得0.99精度\n",
    "TRAINING_ITERATIONS = 2500        \n",
    "    \n",
    "DROPOUT = 0.5\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "# set to 0 to train on all available data\n",
    "# 设置为0以训练所有可用数据\n",
    "VALIDATION_SIZE = 2000\n",
    "\n",
    "# image number to output\n",
    "# 要输出的图像编号\n",
    "IMAGE_TO_DISPLAY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "data(42000,785)\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "# read training data from CSV file \n",
    "data = pd.read_csv('train.csv')\n",
    "print(data.shape)\n",
    "\n",
    "print('data({0[0]},{0[1]})'.format(data.shape))\n",
    "print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "images(42000,784)\n"
     ]
    }
   ],
   "source": [
    "images = data.iloc[:,1:].values\n",
    "print(images.shape)\n",
    "images = images.astype(np.float)\n",
    "print(type(images))\n",
    "\n",
    "# convert from [0:255] => [0.0:1.0]\n",
    "images = np.multiply(images, 1.0 / 255.0)\n",
    "print(type(images))\n",
    "\n",
    "print('images({0[0]},{0[1]})'.format(images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_size => 784\n",
      "image_width => 28\n",
      "image_height => 28\n"
     ]
    }
   ],
   "source": [
    "image_size = images.shape[1]\n",
    "print ('image_size => {0}'.format(image_size))\n",
    "\n",
    "# in this case all images are square\n",
    "# 在这种情况下，所有图像都是正方形的\n",
    "image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "# np.ceil() 计算大于等于该值的最小整数，其实就是向上取整\n",
    "# uint8是无符号八位整型，表示范围是[0, 255]的整数\n",
    "# 如果需要转回PIL的图像对象，那就必须是uint8的格式\n",
    "\n",
    "print ('image_width => {0}\\nimage_height => {1}'.format(image_width,image_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(784,)\n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.02745098 0.09411765 0.09411765 0.38039216 0.99215686 0.99215686\n",
      " 0.99215686 0.99215686 1.         0.70588235 0.18823529 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.11764706 0.72941176 0.98823529\n",
      " 0.98823529 0.99215686 0.98823529 0.98823529 0.98823529 0.98823529\n",
      " 0.99215686 0.98823529 0.89019608 0.11372549 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.14901961 0.60784314 0.98823529 0.98823529 0.98823529 0.99215686\n",
      " 0.98823529 0.98823529 0.89019608 0.30980392 0.87058824 0.98823529\n",
      " 0.98823529 0.50588235 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.33333333 0.91372549 0.98823529\n",
      " 0.98823529 0.98823529 0.98823529 0.99215686 0.98823529 0.98823529\n",
      " 0.79215686 0.04313725 0.70588235 0.98823529 0.98823529 0.46666667\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.16862745 0.94117647 0.99215686 0.98823529 0.98823529 0.98823529\n",
      " 0.98823529 0.99215686 0.98823529 0.98823529 0.95686275 0.49411765\n",
      " 0.78823529 0.98823529 0.98823529 0.58823529 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.02745098 0.83137255 0.99215686\n",
      " 1.         0.99215686 0.99215686 0.99215686 0.90980392 0.86666667\n",
      " 0.16470588 0.         0.40784314 0.99215686 1.         0.99215686\n",
      " 0.80392157 0.08235294 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.09803922 0.8745098  0.98823529 0.99215686 0.98823529\n",
      " 0.98823529 0.83921569 0.07058824 0.         0.         0.13333333\n",
      " 0.84313725 0.98823529 0.99215686 0.8745098  0.21960784 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.38823529 0.96470588 0.99215686 0.98823529 0.98823529 0.30196078\n",
      " 0.         0.02745098 0.2745098  0.79607843 0.98823529 0.98823529\n",
      " 0.67843137 0.09803922 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.16470588\n",
      " 0.99215686 0.98823529 0.98823529 0.9254902  0.40392157 0.62745098\n",
      " 0.98823529 0.98823529 0.85490196 0.42352941 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.58039216 0.98823529\n",
      " 0.98823529 0.98823529 0.98823529 0.99215686 0.90588235 0.41568627\n",
      " 0.05490196 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.09411765 0.99215686 0.99215686 0.99215686\n",
      " 0.99215686 1.         0.62352941 0.02745098 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.16862745\n",
      " 0.4627451  0.98823529 0.94117647 0.95686275 0.98823529 0.99215686\n",
      " 0.90588235 0.14509804 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.0745098  0.64313725 0.96470588 0.99215686 0.73333333\n",
      " 0.19607843 0.38823529 0.96470588 0.99215686 0.98823529 0.27058824\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.31372549\n",
      " 0.90980392 0.98823529 0.79607843 0.22745098 0.         0.\n",
      " 0.52941176 0.99215686 0.98823529 0.4745098  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.16862745 0.96470588 0.98823529 0.78431373\n",
      " 0.04313725 0.         0.         0.         0.45490196 0.99215686\n",
      " 0.98823529 0.27058824 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.63529412 0.99215686 0.75294118 0.04313725 0.         0.\n",
      " 0.         0.         0.70196078 1.         0.99215686 0.27058824\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.01960784 0.69803922 0.98823529\n",
      " 0.46666667 0.         0.01960784 0.18431373 0.18431373 0.54901961\n",
      " 0.95686275 0.99215686 0.98823529 0.27058824 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.02745098 0.72941176 0.98823529 0.89019608 0.72156863\n",
      " 0.74901961 0.98823529 0.98823529 0.98823529 0.98823529 0.99215686\n",
      " 0.94117647 0.19607843 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.04313725\n",
      " 0.56470588 0.89019608 0.98823529 0.98823529 0.99215686 0.98823529\n",
      " 0.98823529 0.98823529 0.98823529 0.38431373 0.14509804 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.18823529\n",
      " 0.5372549  0.94901961 0.99215686 0.90588235 0.5372549  0.5372549\n",
      " 0.1254902  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display(img):\n",
    "    \n",
    "    # (784) => (28,28)\n",
    "    one_image = img.reshape(image_width,image_height)  # 需要将其转换成一种图像的格式，才可以进行后面imshow图像的展示，图像是由长和宽组成的\n",
    "    \n",
    "    plt.axis('off')\n",
    "    # plt.gray()：只有黑白两色，没有中间的渐进色\n",
    "    # 1. 关闭坐标刻度  plt.xticks([]) plt.yticks([])   关闭坐标轴：plt.axis('off')\n",
    "    # 注意，类似的这些操作若想起作用，需要将其置于 plt.show() 之前，plt.imshow() 之后。\n",
    "    # 2. 设置所要保存图像的 dpi  dpi：Dots Per Inch  plt.savefig(..., dpi=150)\n",
    "    # 3. 坐标轴不可见\n",
    "    # frame = plt.gca()\n",
    "    # y 轴不可见\n",
    "    # frame.axes.get_yaxis().set_visible(False)\n",
    "    # x 轴不可见\n",
    "    # frame.axes.get_xaxis().set_visible(False)\n",
    "    plt.imshow(one_image, cmap=cm.binary)    \n",
    "\n",
    "# output image  \n",
    "# 要输出的图像编号\n",
    "# IMAGE_TO_DISPLAY = 10\n",
    "print(images.shape)\n",
    "print(images[IMAGE_TO_DISPLAY].shape)\n",
    "print(images[IMAGE_TO_DISPLAY])\n",
    "display(images[IMAGE_TO_DISPLAY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n",
      "(42000,)\n",
      "<class 'numpy.ndarray'>\n",
      "(42000,)\n",
      "labels_flat(42000)\n",
      "labels_flat[10] => 8\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "# labels_flat = data[[0]].values.ravel()\n",
    "print(data.iloc[:,0].values.shape)\n",
    "labels_flat = data.iloc[:,0].values.ravel()\n",
    "print(type(labels_flat))\n",
    "print(labels_flat.shape)\n",
    "\n",
    "print('labels_flat({0})'.format(len(labels_flat)))\n",
    "print ('labels_flat[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels_flat[IMAGE_TO_DISPLAY]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(10,)\n",
      "labels_count => 10\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(labels_flat))\n",
    "print(np.unique(labels_flat).shape)\n",
    "labels_count = np.unique(labels_flat).shape[0]\n",
    "\n",
    "print('labels_count => {0}'.format(labels_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0     10     20 ... 419970 419980 419990]\n",
      "(42000,)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(42000, 10)\n",
      "[1 0 1 ... 7 6 9]\n",
      "<class 'numpy.ndarray'>\n",
      "[     1     10     21 ... 419977 419986 419999]\n",
      "(42000,)\n",
      "别逼我了\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(42000,)\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "(42000, 10)\n",
      "labels(42000,10)\n",
      "labels[10] => [0 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# convert class labels from scalars to one-hot vectors\n",
    "# 将类标签从标量转换为一键矢量\n",
    "# 0 => [1 0 0 0 0 0 0 0 0 0]\n",
    "# 1 => [0 1 0 0 0 0 0 0 0 0]\n",
    "# ...\n",
    "# 9 => [0 0 0 0 0 0 0 0 0 1]\n",
    "def dense_to_one_hot(labels_dense, num_classes):\n",
    "    num_labels = labels_dense.shape[0]  # 42000\n",
    "    index_offset = np.arange(num_labels) * num_classes  \n",
    "    print(index_offset)\n",
    "    print(index_offset.shape)\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "    print(labels_one_hot)\n",
    "    print(labels_one_hot.shape)\n",
    "    print(labels_dense.ravel())  # 就是将标签给扁平化处理了呗\n",
    "    print(type(labels_one_hot))\n",
    "    print(index_offset + labels_dense.ravel())\n",
    "    print((index_offset + labels_dense.ravel()).shape)\n",
    "    print('别逼我了')\n",
    "    print(labels_one_hot.flat[index_offset + labels_dense.ravel()]) # 这些项都被取出来了，后面赋值为1\n",
    "    # flat本身是数组重组的意思，这里是起到一个赋值的作用\n",
    "    print((labels_one_hot.flat[index_offset + labels_dense.ravel()]).shape)\n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "    print(labels_one_hot)\n",
    "    print(labels_one_hot.shape)\n",
    "    return labels_one_hot\n",
    "\n",
    "labels = dense_to_one_hot(labels_flat, labels_count)  # labels_flat为(42000,)，labels_count为10\n",
    "labels = labels.astype(np.uint8)\n",
    "\n",
    "print('labels({0[0]},{0[1]})'.format(labels.shape))\n",
    "print ('labels[{0}] => {1}'.format(IMAGE_TO_DISPLAY,labels[IMAGE_TO_DISPLAY]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images(40000,784)\n",
      "validation_images(2000,784)\n"
     ]
    }
   ],
   "source": [
    "# split data into training & validation\n",
    "# 将数据分为训练集和验证集\n",
    "# VALIDATION_SIZE = 2000  这是验证集的大小\n",
    "validation_images = images[:VALIDATION_SIZE]\n",
    "validation_labels = labels[:VALIDATION_SIZE]\n",
    "\n",
    "train_images = images[VALIDATION_SIZE:]\n",
    "train_labels = labels[VALIDATION_SIZE:]\n",
    "\n",
    "\n",
    "print('train_images({0[0]},{0[1]})'.format(train_images.shape))\n",
    "print('validation_images({0[0]},{0[1]})'.format(validation_images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight initialization\n",
    "# 权重初始化\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)  # 初始化用高斯分布\n",
    "    # tf.truncated_normal与tf.random_normal的作用都是从给定均值和方差的正态分布中输出变量。两者的区别在于tf.truncated_normal 截取的是两个标\n",
    "    # 准差以内的部分，换句话说就是截取随机变量更接近于均值。\n",
    "    return tf.Variable(initial) # 这一步必不可少，转化为tf支持的格式\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)  # 初始化用常量\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):  # 卷积\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    # tf.nn.conv2d就是对原始的数据进行卷积的操作\n",
    "    # x就是输入\n",
    "    # W就相当于是一个小的窗口，用两个小的窗口去求这样一个内积的操作\n",
    "    # strides是说卷积怎么滑，中间两个1是说沿着长和宽都是1*1的，左边和右边的1分别代表是在batch上和在channel上怎么1 \n",
    "    # 如果你想一次性移动2*2的单元格，把中间两个1都改成2就可以了，两旁的1一般不改变\n",
    "    # padding是指填充的意思，在原始图像上进行边缘填充\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooling\n",
    "# [[0,3],\n",
    "#  [4,2]] => 4\n",
    "\n",
    "# [[0,1],\n",
    "#  [1,1]] => 1\n",
    "\n",
    "def max_pool_2x2(x):  # 池化\n",
    "    # 这个应该是池化的操作，对当前的特征图也是进行一次特征的提取，只把最大的值保留出来，其他的值全要过滤掉，为了使得我们的特征图能够\n",
    "    # 进行一个压缩的操作\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    # x还是输入的意思，strides还是指滑动的步长\n",
    "    # ksize是说要指定一个多大的窗口，指定一个2*2，就是说要在2*2的区域里去找这样一个最大的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 784)\n",
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "# input & output of NN\n",
    "\n",
    "# images\n",
    "# 输入就是由像素点组成的矩阵\n",
    "# BATCH_SIZE = 50\n",
    "x = tf.placeholder('float', shape=[None, image_size])  # 先不指定实际的batch是多大的，先占一个坑再说，坑里有多少个数据暂时不知道，先把结构给定义出来\n",
    "print(x.shape)\n",
    "# labels\n",
    "y_ = tf.placeholder('float', shape=[None, labels_count])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first convolutional layer\n",
    "# 第一卷积层\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])  \n",
    "# W是滑动窗口特征提取的作用，从W1-W32，最终可以得到32组特征，这32组特征项堆叠起来得到一个新的特征图，在新的特征图上深度就是等于32的\n",
    "# 在原始图像上找的窗口的大小是5*5，W前面连的输入深度/channel是1，32指后面想得到多少个特征图\n",
    "# 32就是指你最终想得到多少个特征图\n",
    "b_conv1 = bias_variable([32]) \n",
    "# 32个特征图中每个特征图都会有一个b\n",
    "\n",
    "# (40000,784) => (40000,28,28,1)\n",
    "image = tf.reshape(x, [-1,image_width , image_height,1])  # batch_size用-1来表示，是实际推断出来的\n",
    "# 在计算时需要将输入，就是image稍微做一些改变\n",
    "#print (image.get_shape()) # =>(40000,28,28,1)\n",
    "\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(image, W_conv1) + b_conv1)\n",
    "#print (h_conv1.get_shape()) # => (40000, 28, 28, 32)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "#print (h_pool1.get_shape()) # => (40000, 14, 14, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 32, 64)\n",
      "(?, 14, 14, 64)\n",
      "(?, 7, 7, 64)\n"
     ]
    }
   ],
   "source": [
    "# second convolutional layer\n",
    "# 第二卷积层\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "print(W_conv2.shape)\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) # 卷积\n",
    "print(h_conv2.shape)\n",
    "#print (h_conv2.get_shape()) # => (40000, 14,14, 64)\n",
    "h_pool2 = max_pool_2x2(h_conv2)  # 卷积完后再经过一层池化层进行一个特征的再压缩\n",
    "print(h_pool2.shape)\n",
    "#print (h_pool2.get_shape()) # => (40000, 7, 7, 64)\n",
    "# 大小是7*7的，用64个这样7*7的大小，形成了这样一个特征图\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3136, 1024)\n",
      "(1024,)\n",
      "(?, 3136)\n",
      "(?, 1024)\n"
     ]
    }
   ],
   "source": [
    "# 准备进行权连接(wx+b)的操作，因为特征图是利用不了的，要将特征图转化为向量的格式进行操作\n",
    "# densely connected layer\n",
    "# 紧密连接层\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])  # 想得到一个1024维的向量\n",
    "print(W_fc1.shape)\n",
    "b_fc1 = bias_variable([1024])\n",
    "print(b_fc1.shape)\n",
    "\n",
    "# (40000, 7, 7, 64) => (40000, 3136)\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "print(h_pool2_flat.shape)\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)   # 就是为了将维度转化为1024啊，维度其实就是特征图的意思吧\n",
    "print(h_fc1.shape)\n",
    "#print (h_fc1.get_shape()) # => (40000, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 1024)\n"
     ]
    }
   ],
   "source": [
    "# dropout\n",
    "keep_prob = tf.placeholder('float')  # 要设置一个保留率\n",
    "print(type(keep_prob))\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "print(type(h_fc1_drop))\n",
    "print(h_fc1_drop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 10)\n",
      "(?, 10)\n"
     ]
    }
   ],
   "source": [
    "# readout layer for deep net\n",
    "# 深度网络的输出层\n",
    "W_fc2 = weight_variable([1024, labels_count])  # labels_count=10\n",
    "print(W_fc2.shape)\n",
    "b_fc2 = bias_variable([labels_count])\n",
    "\n",
    "y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)  # 将1024维转化为10维输出，维度其实就是特征图的意思吧\n",
    "print(y.shape)\n",
    "\n",
    "#print (y.get_shape()) # => (40000, 10)\n",
    "\n",
    "# 卷积池化神经网络是有很多特征提取和最终特征整合的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "# 成本函数\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))  # 用了一种交叉熵的形式  \n",
    "# 这是softmax的损失函数表示么\n",
    "# tf.reduce_sum ：计算tensor指定轴方向上的所有元素的累加和\n",
    "# tf.reduce_max  :  计算tensor指定轴方向上的各个元素的最大值\n",
    "# tf.reduce_all :  计算tensor指定轴方向上的各个元素的逻辑和（and运算）\n",
    "# tf.reduce_any:  计算tensor指定轴方向上的各个元素的逻辑或（or运算）\n",
    "\n",
    "\n",
    "# optimisation function\n",
    "# 优化函数 优化器\n",
    "# LEARNING_RATE = 1e-4\n",
    "train_step = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(cross_entropy)  # 这里是梯度下降的优化方式，要最小化损失函数\n",
    "\n",
    "# evaluation\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))  # 用tf.equal来预测一下预测值和真实值是否相等\n",
    "# tf.argmax(input,axis)根据axis取值的不同返回每行或者每列最大值的索引\n",
    "# axis=0时比较每一列的元素，将每一列最大元素所在的索引记录下来，最后输出每一列最大元素所在的索引数组\n",
    "# axis=1的时候，将每一行最大元素所在的索引记录下来，最后返回每一行最大元素所在的索引数组\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "# tf.cast()函数的作用是执行 tensorflow 中张量数据类型转换，比如读入的图片如果是int8类型的，一般在要在训练前把图像的数据格式转换为float32\n",
    "# tf.reduce_mean 函数用于计算张量tensor沿着指定的数轴（tensor的某一维度）上的的平均值，主要用作降维或者计算tensor（图像）的平均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax_6:0\", shape=(?,), dtype=int64)\n",
      "(?,)\n"
     ]
    }
   ],
   "source": [
    "# prediction function\n",
    "#[0.1, 0.9, 0.2, 0.1, 0.1 0.3, 0.5, 0.1, 0.2, 0.3] => 1\n",
    "predict = tf.argmax(y,1)\n",
    "print(predict)\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_completed = 0  # 迭代完成\n",
    "index_in_epoch = 0  # 迭代的索引\n",
    "# train_images = images[VALIDATION_SIZE:]\n",
    "# train_images(40000,784)\n",
    "num_examples = train_images.shape[0]  # 这个指样本训练集的数量，就是40000\n",
    "\n",
    "# serve data by batches\n",
    "# 分批提供数据\n",
    "# BATCH_SIZE = 50\n",
    "def next_batch(batch_size):\n",
    "    \n",
    "    global train_images\n",
    "    global train_labels\n",
    "    global index_in_epoch\n",
    "    global epochs_completed\n",
    "    \n",
    "    start = index_in_epoch  # 一开始是0\n",
    "    index_in_epoch += batch_size  # 迭代的索引是随着子训练集增加的，每一次循环增加一个子训练集的数量\n",
    "    \n",
    "    # when all trainig data have been already used, it is reorder randomly    \n",
    "    # 当所有训练数据都已使用后，将对其随机重新排序\n",
    "    if index_in_epoch > num_examples:\n",
    "        # finished epoch\n",
    "        # 结束迭代\n",
    "        epochs_completed += 1  # 这就完成了一次epoch了\n",
    "        # shuffle the data\n",
    "        # 随机整理数据\n",
    "        perm = np.arange(num_examples) \n",
    "        np.random.shuffle(perm)  # 这不很明显是把数据的索引给打乱了么\n",
    "        train_images = train_images[perm]  # 顺序打乱了后这就是新的训练数据\n",
    "        train_labels = train_labels[perm]  # 顺序打乱了后这就是新的训练数据标签\n",
    "        # start next epoch\n",
    "        # 开始下一个epoch\n",
    "        start = 0\n",
    "        index_in_epoch = batch_size  # 还是会选择一个batch一个batch的迭代\n",
    "        assert batch_size <= num_examples  # 这个是断言\n",
    "    end = index_in_epoch\n",
    "    return train_images[start:end], train_labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "# start TensorFlow session\n",
    "# 开始TensorFlow会话\n",
    "init = tf.initialize_all_variables()  # 对于tf变量来说，初始化必不可少，这里初始化所有定义的变量\n",
    "sess = tf.InteractiveSession()  # 指定这样一个交互的图结构\n",
    "# 在tensorflow当中，找一个可以计算的图的区域，tensorflow所有的结构都是一种图的结构，找这样一个计算区域帮我们去算这个事儿\n",
    "\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_accuracy / validation_accuracy => 0.12 / 0.16 for step 0\n",
      "training_accuracy / validation_accuracy => 0.18 / 0.16 for step 1\n",
      "training_accuracy / validation_accuracy => 0.20 / 0.12 for step 2\n",
      "training_accuracy / validation_accuracy => 0.10 / 0.16 for step 3\n",
      "training_accuracy / validation_accuracy => 0.06 / 0.14 for step 4\n",
      "training_accuracy / validation_accuracy => 0.18 / 0.28 for step 5\n",
      "training_accuracy / validation_accuracy => 0.16 / 0.30 for step 6\n",
      "training_accuracy / validation_accuracy => 0.32 / 0.34 for step 7\n",
      "training_accuracy / validation_accuracy => 0.38 / 0.32 for step 8\n",
      "training_accuracy / validation_accuracy => 0.24 / 0.36 for step 9\n",
      "training_accuracy / validation_accuracy => 0.48 / 0.32 for step 10\n",
      "training_accuracy / validation_accuracy => 0.38 / 0.54 for step 20\n",
      "training_accuracy / validation_accuracy => 0.52 / 0.60 for step 30\n",
      "training_accuracy / validation_accuracy => 0.42 / 0.58 for step 40\n",
      "training_accuracy / validation_accuracy => 0.70 / 0.68 for step 50\n",
      "training_accuracy / validation_accuracy => 0.60 / 0.68 for step 60\n",
      "training_accuracy / validation_accuracy => 0.78 / 0.76 for step 70\n",
      "training_accuracy / validation_accuracy => 0.70 / 0.72 for step 80\n",
      "training_accuracy / validation_accuracy => 0.74 / 0.78 for step 90\n",
      "training_accuracy / validation_accuracy => 0.88 / 0.80 for step 100\n",
      "training_accuracy / validation_accuracy => 0.92 / 0.92 for step 200\n",
      "training_accuracy / validation_accuracy => 0.84 / 0.94 for step 300\n",
      "training_accuracy / validation_accuracy => 0.92 / 0.94 for step 400\n",
      "training_accuracy / validation_accuracy => 0.96 / 0.94 for step 500\n",
      "training_accuracy / validation_accuracy => 0.90 / 0.94 for step 600\n",
      "training_accuracy / validation_accuracy => 0.84 / 0.94 for step 700\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.94 for step 800\n",
      "training_accuracy / validation_accuracy => 0.98 / 0.94 for step 900\n",
      "training_accuracy / validation_accuracy => 0.94 / 0.94 for step 1000\n",
      "training_accuracy / validation_accuracy => 0.96 / 0.96 for step 2000\n",
      "training_accuracy / validation_accuracy => 0.96 / 0.98 for step 2499\n"
     ]
    }
   ],
   "source": [
    "# visualisation variables\n",
    "# 可视化变量\n",
    "train_accuracies = []  # 训练集精度\n",
    "validation_accuracies = []  # 验证集精度\n",
    "x_range = []  # x的范围\n",
    "\n",
    "display_step=1  # 显示步骤\n",
    "\n",
    "for i in range(TRAINING_ITERATIONS):  # TRAINING_ITERATIONS = 2500\n",
    "\n",
    "    # get new batch\n",
    "    # BATCH_SIZE = 50\n",
    "    batch_xs, batch_ys = next_batch(BATCH_SIZE)   # 每次迭代后batch_xs, batch_ys应该是都会有所变化的，样本训练集的数量有40000份呢\n",
    "    # next_batch(batch_size)返回的是train_images[start:end], train_labels[start:end]\n",
    "\n",
    "    # check progress on every 1st,2nd,...,10th,20th,...,100th... step\n",
    "    # 每1、2，...，10、20，...，100 ...步骤检查进度\n",
    "    # 看一下当前的结果在训练集和验证集上的效果怎么样\n",
    "    # display_step=10后，i就直接跳到了20,30...100才满足\n",
    "    # display_step=100后，i就直接跳到了200...1000才满足\n",
    "    # display_step=1000后，i就直接跳到了2000才满足，外加一个2449\n",
    "    if i%display_step == 0 or (i+1) == TRAINING_ITERATIONS:  # i%display_step,求余，就是整除，或者就是i=2449\n",
    "        \n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch_xs, \n",
    "                                                  y_: batch_ys, \n",
    "                                                  keep_prob: 1.0})       \n",
    "        if(VALIDATION_SIZE):  # VALIDATION_SIZE = 2000  2000/50 = 40  这里应该是只要VALIDATION_SIZE不为0即满足条件\n",
    "            # validation_images = images[:VALIDATION_SIZE]  validation_images(2000,784)\n",
    "            # validation_labels = labels[:VALIDATION_SIZE]\n",
    "            validation_accuracy = accuracy.eval(feed_dict={ x: validation_images[0:BATCH_SIZE], \n",
    "                                                            y_: validation_labels[0:BATCH_SIZE], \n",
    "                                                            keep_prob: 1.0})\n",
    "            # 这里才是让我费解的点，因为验证集一共有2000份，但是validation_images[0:BATCH_SIZE]这个东西每次不是不变的么\n",
    "            # 所以吧，每次打出的都是验证同一份验证集的精度\n",
    "            print('training_accuracy / validation_accuracy => %.2f / %.2f for step %d'%(train_accuracy, validation_accuracy, i))\n",
    "            \n",
    "            validation_accuracies.append(validation_accuracy)\n",
    "            \n",
    "        else:  # 这个从未用到，也不知道摆在这里干嘛\n",
    "             print('training_accuracy => %.4f for step %d'%(train_accuracy, i))\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        x_range.append(i)\n",
    "        \n",
    "        # increase display_step\n",
    "        # display_step变成10后，i就直接跳到了100才满足\n",
    "        # display_step变成100后，i就直接跳到了1000才满足，然后就没有然后了，迭代完毕\n",
    "        if i%(display_step*10) == 0 and i:  # 0%10 = 0并且i不为0才行，也就是说要是能整除10的数，首先就是10自己\n",
    "            display_step *= 10  # display_step从1变成了10\n",
    "    # train on batch\n",
    "    # 在子训练集上进行训练\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys, keep_prob: DROPOUT})\n",
    "    # 这一步太重要了吧，是解决一切关键问题的关键，同时也解释了为什么每次都要使用下一份训练集进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_accuracy => 0.9705\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check final accuracy on validation set \n",
    "# 检查验证集的最终准确性\n",
    "if(VALIDATION_SIZE):\n",
    "    validation_accuracy = accuracy.eval(feed_dict={x: validation_images, \n",
    "                                                   y_: validation_labels, \n",
    "                                                   keep_prob: 1.0})\n",
    "    print('validation_accuracy => %.4f'%validation_accuracy)\n",
    "    plt.plot(x_range, train_accuracies,'-b', label='Training')\n",
    "    plt.plot(x_range, validation_accuracies,'-g', label='Validation')\n",
    "    plt.legend(loc='lower right', frameon=False)  # 删除框中的图  frameon=False\n",
    "    # plt.legend(loc='lower right', frameon=True)\n",
    "    # plt.ylim(ymax = 1.1, ymin = 0.7)\n",
    "    plt.ylim(top = 1.1, bottom = 0.7)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('step')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " 474241623"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
