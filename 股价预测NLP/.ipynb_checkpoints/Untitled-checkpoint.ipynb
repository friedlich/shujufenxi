{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # 文本特征提取 \n",
    "# 文本分析是机器学习算法的主要应用领域。但是，文本分析的原始数据无法直接丢给算法，这些原始数据是一组符号，因为大多数算法期望的输入是固定长度\n",
    "# 的数值特征向量而不是不同长度的文本文件。为了解决这个问题，scikit-learn提供了一些实用工具可以用最常见的方式从文本内容中抽取数值特征\n",
    "# 将文档文件转化为数值特征的一般过程被称为向量化\n",
    "# 通用向量使用\n",
    "# CountVectorizer在一个类中实现了标记和计数\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Combined_News_DJIA.csv')   # Gensim库里面提供了许多转化vector的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
       "      <td>b'Russian tanks are moving towards the capital...</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
       "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
       "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
       "      <td>b'This is a busy day:  The European Union has ...</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
       "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
       "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
       "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
       "      <td>b' Russia has just beaten the United States ov...</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0</td>\n",
       "      <td>b'Remember that adorable 9-year-old who sang a...</td>\n",
       "      <td>b\"Russia 'ends Georgia operation'\"</td>\n",
       "      <td>b'\"If we had no sexual harassment we would hav...</td>\n",
       "      <td>b\"Al-Qa'eda is losing support in Iraq because ...</td>\n",
       "      <td>b'Ceasefire in Georgia: Putin Outmaneuvers the...</td>\n",
       "      <td>b'Why Microsoft and Intel tried to kill the XO...</td>\n",
       "      <td>b'Stratfor: The Russo-Georgian War and the Bal...</td>\n",
       "      <td>b\"I'm Trying to Get a Sense of This Whole Geor...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'U.S. troops still in Georgia (did you know t...</td>\n",
       "      <td>b'Why Russias response to Georgia was right'</td>\n",
       "      <td>b'Gorbachev accuses U.S. of making a \"serious ...</td>\n",
       "      <td>b'Russia, Georgia, and NATO: Cold War Two'</td>\n",
       "      <td>b'Remember that adorable 62-year-old who led y...</td>\n",
       "      <td>b'War in Georgia: The Israeli connection'</td>\n",
       "      <td>b'All signs point to the US encouraging Georgi...</td>\n",
       "      <td>b'Christopher King argues that the US and NATO...</td>\n",
       "      <td>b'America: The New Mexico?'</td>\n",
       "      <td>b\"BBC NEWS | Asia-Pacific | Extinction 'by man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0</td>\n",
       "      <td>b' U.S. refuses Israel weapons to attack Iran:...</td>\n",
       "      <td>b\"When the president ordered to attack Tskhinv...</td>\n",
       "      <td>b' Israel clears troops who killed Reuters cam...</td>\n",
       "      <td>b'Britain\\'s policy of being tough on drugs is...</td>\n",
       "      <td>b'Body of 14 year old found in trunk; Latest (...</td>\n",
       "      <td>b'China has moved 10 *million* quake survivors...</td>\n",
       "      <td>b\"Bush announces Operation Get All Up In Russi...</td>\n",
       "      <td>b'Russian forces sink Georgian ships '</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Elephants extinct by 2020?'</td>\n",
       "      <td>b'US humanitarian missions soon in Georgia - i...</td>\n",
       "      <td>b\"Georgia's DDOS came from US sources\"</td>\n",
       "      <td>b'Russian convoy heads into Georgia, violating...</td>\n",
       "      <td>b'Israeli defence minister: US against strike ...</td>\n",
       "      <td>b'Gorbachev: We Had No Choice'</td>\n",
       "      <td>b'Witness: Russian forces head towards Tbilisi...</td>\n",
       "      <td>b' Quarter of Russians blame U.S. for conflict...</td>\n",
       "      <td>b'Georgian president  says US military will ta...</td>\n",
       "      <td>b'2006: Nobel laureate Aleksander Solzhenitsyn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>1</td>\n",
       "      <td>b'All the experts admit that we should legalis...</td>\n",
       "      <td>b'War in South Osetia - 89 pictures made by a ...</td>\n",
       "      <td>b'Swedish wrestler Ara Abrahamian throws away ...</td>\n",
       "      <td>b'Russia exaggerated the death toll in South O...</td>\n",
       "      <td>b'Missile That Killed 9 Inside Pakistan May Ha...</td>\n",
       "      <td>b\"Rushdie Condemns Random House's Refusal to P...</td>\n",
       "      <td>b'Poland and US agree to missle defense deal. ...</td>\n",
       "      <td>b'Will the Russians conquer Tblisi? Bet on it,...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Bank analyst forecast Georgian crisis 2 days...</td>\n",
       "      <td>b\"Georgia confict could set back Russia's US r...</td>\n",
       "      <td>b'War in the Caucasus is as much the product o...</td>\n",
       "      <td>b'\"Non-media\" photos of South Ossetia/Georgia ...</td>\n",
       "      <td>b'Georgian TV reporter shot by Russian sniper ...</td>\n",
       "      <td>b'Saudi Arabia: Mother moves to block child ma...</td>\n",
       "      <td>b'Taliban wages war on humanitarian aid workers'</td>\n",
       "      <td>b'Russia: World  \"can forget about\" Georgia\\'s...</td>\n",
       "      <td>b'Darfur rebels accuse Sudan of mounting major...</td>\n",
       "      <td>b'Philippines : Peace Advocate say Muslims nee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n",
       "1  2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n",
       "2  2008-08-12      0  b'Remember that adorable 9-year-old who sang a...   \n",
       "3  2008-08-13      0  b' U.S. refuses Israel weapons to attack Iran:...   \n",
       "4  2008-08-14      1  b'All the experts admit that we should legalis...   \n",
       "\n",
       "                                                Top2  \\\n",
       "0            b'BREAKING: Musharraf to be impeached.'   \n",
       "1        b'Bush puts foot down on Georgian conflict'   \n",
       "2                 b\"Russia 'ends Georgia operation'\"   \n",
       "3  b\"When the president ordered to attack Tskhinv...   \n",
       "4  b'War in South Osetia - 89 pictures made by a ...   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  b'Russia Today: Columns of troops roll into So...   \n",
       "1  b\"Jewish Georgian minister: Thanks to Israeli ...   \n",
       "2  b'\"If we had no sexual harassment we would hav...   \n",
       "3  b' Israel clears troops who killed Reuters cam...   \n",
       "4  b'Swedish wrestler Ara Abrahamian throws away ...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  b'Russian tanks are moving towards the capital...   \n",
       "1  b'Georgian army flees in disarray as Russians ...   \n",
       "2  b\"Al-Qa'eda is losing support in Iraq because ...   \n",
       "3  b'Britain\\'s policy of being tough on drugs is...   \n",
       "4  b'Russia exaggerated the death toll in South O...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  b\"Afghan children raped with 'impunity,' U.N. ...   \n",
       "1      b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "2  b'Ceasefire in Georgia: Putin Outmaneuvers the...   \n",
       "3  b'Body of 14 year old found in trunk; Latest (...   \n",
       "4  b'Missile That Killed 9 Inside Pakistan May Ha...   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  b'150 Russian tanks have entered South Ossetia...   \n",
       "1  b'What were the Mossad with fraudulent New Zea...   \n",
       "2  b'Why Microsoft and Intel tried to kill the XO...   \n",
       "3  b'China has moved 10 *million* quake survivors...   \n",
       "4  b\"Rushdie Condemns Random House's Refusal to P...   \n",
       "\n",
       "                                                Top7  \\\n",
       "0  b\"Breaking: Georgia invades South Ossetia, Rus...   \n",
       "1  b'Russia angered by Israeli military sale to G...   \n",
       "2  b'Stratfor: The Russo-Georgian War and the Bal...   \n",
       "3  b\"Bush announces Operation Get All Up In Russi...   \n",
       "4  b'Poland and US agree to missle defense deal. ...   \n",
       "\n",
       "                                                Top8  ...  \\\n",
       "0  b\"The 'enemy combatent' trials are nothing but...  ...   \n",
       "1  b'An American citizen living in S.Ossetia blam...  ...   \n",
       "2  b\"I'm Trying to Get a Sense of This Whole Geor...  ...   \n",
       "3             b'Russian forces sink Georgian ships '  ...   \n",
       "4  b'Will the Russians conquer Tblisi? Bet on it,...  ...   \n",
       "\n",
       "                                               Top16  \\\n",
       "0  b'Georgia Invades South Ossetia - if Russia ge...   \n",
       "1  b'Israel and the US behind the Georgian aggres...   \n",
       "2  b'U.S. troops still in Georgia (did you know t...   \n",
       "3                      b'Elephants extinct by 2020?'   \n",
       "4  b'Bank analyst forecast Georgian crisis 2 days...   \n",
       "\n",
       "                                               Top17  \\\n",
       "0                b'Al-Qaeda Faces Islamist Backlash'   \n",
       "1  b'\"Do not believe TV, neither Russian nor Geor...   \n",
       "2       b'Why Russias response to Georgia was right'   \n",
       "3  b'US humanitarian missions soon in Georgia - i...   \n",
       "4  b\"Georgia confict could set back Russia's US r...   \n",
       "\n",
       "                                               Top18  \\\n",
       "0  b'Condoleezza Rice: \"The US would not act to p...   \n",
       "1  b'Riots are still going on in Montreal (Canada...   \n",
       "2  b'Gorbachev accuses U.S. of making a \"serious ...   \n",
       "3             b\"Georgia's DDOS came from US sources\"   \n",
       "4  b'War in the Caucasus is as much the product o...   \n",
       "\n",
       "                                               Top19  \\\n",
       "0  b'This is a busy day:  The European Union has ...   \n",
       "1    b'China to overtake US as largest manufacturer'   \n",
       "2         b'Russia, Georgia, and NATO: Cold War Two'   \n",
       "3  b'Russian convoy heads into Georgia, violating...   \n",
       "4  b'\"Non-media\" photos of South Ossetia/Georgia ...   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  b\"Georgia will withdraw 1,000 soldiers from Ir...   \n",
       "1                     b'War in South Ossetia [PICS]'   \n",
       "2  b'Remember that adorable 62-year-old who led y...   \n",
       "3  b'Israeli defence minister: US against strike ...   \n",
       "4  b'Georgian TV reporter shot by Russian sniper ...   \n",
       "\n",
       "                                               Top21  \\\n",
       "0  b'Why the Pentagon Thinks Attacking Iran is a ...   \n",
       "1  b'Israeli Physicians Group Condemns State Tort...   \n",
       "2          b'War in Georgia: The Israeli connection'   \n",
       "3                     b'Gorbachev: We Had No Choice'   \n",
       "4  b'Saudi Arabia: Mother moves to block child ma...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  b'Caucasus in crisis: Georgia invades South Os...   \n",
       "1  b' Russia has just beaten the United States ov...   \n",
       "2  b'All signs point to the US encouraging Georgi...   \n",
       "3  b'Witness: Russian forces head towards Tbilisi...   \n",
       "4   b'Taliban wages war on humanitarian aid workers'   \n",
       "\n",
       "                                               Top23  \\\n",
       "0  b'Indian shoe manufactory  - And again in a se...   \n",
       "1  b'Perhaps *the* question about the Georgia - R...   \n",
       "2  b'Christopher King argues that the US and NATO...   \n",
       "3  b' Quarter of Russians blame U.S. for conflict...   \n",
       "4  b'Russia: World  \"can forget about\" Georgia\\'s...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0  b'Visitors Suffering from Mental Illnesses Ban...   \n",
       "1                 b'Russia is so much better at war'   \n",
       "2                        b'America: The New Mexico?'   \n",
       "3  b'Georgian president  says US military will ta...   \n",
       "4  b'Darfur rebels accuse Sudan of mounting major...   \n",
       "\n",
       "                                               Top25  \n",
       "0           b\"No Help for Mexico's Kidnapping Surge\"  \n",
       "1  b\"So this is what it's come to: trading sex fo...  \n",
       "2  b\"BBC NEWS | Asia-Pacific | Extinction 'by man...  \n",
       "3  b'2006: Nobel laureate Aleksander Solzhenitsyn...  \n",
       "4  b'Philippines : Peace Advocate say Muslims nee...  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 27)\n",
      "(378, 27)\n"
     ]
    }
   ],
   "source": [
    "train = data[data['Date'] < '2015-01-01']\n",
    "print(train.shape)\n",
    "test = data[data['Date'] > '2014-12-31']\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"The commander of a Navy air reconnaissance squadron that provides the President and the defense secretary the airborne ability to command the nation's nuclear weapons has been relieved of duty\"\n"
     ]
    }
   ],
   "source": [
    "example = train.iloc[3,10]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"the commander of a navy air reconnaissance squadron that provides the president and the defense secretary the airborne ability to command the nation's nuclear weapons has been relieved of duty\"\n"
     ]
    }
   ],
   "source": [
    "example2 = example.lower()\n",
    "print(example2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'commander', 'of', 'navy', 'air', 'reconnaissance', 'squadron', 'that', 'provides', 'the', 'president', 'and', 'the', 'defense', 'secretary', 'the', 'airborne', 'ability', 'to', 'command', 'the', 'nation', 'nuclear', 'weapons', 'has', 'been', 'relieved', 'of', 'duty']\n"
     ]
    }
   ],
   "source": [
    "# 标记（tokenizing）  vectorizer = CountVectorizer(min_df=1)\n",
    "# 默认设置通过抽取2个字符以上的词标记字符。完成这个步骤的具体函数可以直接调用：analyze = vectorizer.build_analyzer()\n",
    "example3 = CountVectorizer().build_tokenizer()(example2)  # 这里要build一下这个分词器\n",
    "# 通用向量使用  CountVectorizer在一个类中实现了标记和计数，这个模型有许多参数，不过默认值已经非常合理\n",
    "print(example3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'provides', 'duty', 'the', 'weapons', 'of', 'president', 'and', 'command', 'nation', 'relieved', 'squadron', 'navy', 'defense', 'commander', 'been', 'ability', 'reconnaissance', 'has', 'air', 'that', 'nuclear', 'to', 'airborne', 'secretary'}\n",
      "[['provides', 1], ['duty', 1], ['the', 5], ['weapons', 1], ['of', 2], ['president', 1], ['and', 1], ['command', 1], ['nation', 1], ['relieved', 1], ['squadron', 1], ['navy', 1], ['defense', 1], ['commander', 1], ['been', 1], ['ability', 1], ['reconnaissance', 1], ['has', 1], ['air', 1], ['that', 1], ['nuclear', 1], ['to', 1], ['airborne', 1], ['secretary', 1]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>provides</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>duty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>the</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>weapons</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>of</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>president</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>command</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>nation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>relieved</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>squadron</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>navy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>defense</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>commander</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>been</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>ability</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>reconnaissance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>has</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>air</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>that</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>to</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>airborne</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>secretary</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Word  Count\n",
       "0         provides      1\n",
       "1             duty      1\n",
       "2              the      5\n",
       "3          weapons      1\n",
       "4               of      2\n",
       "5        president      1\n",
       "6              and      1\n",
       "7          command      1\n",
       "8           nation      1\n",
       "9         relieved      1\n",
       "10        squadron      1\n",
       "11            navy      1\n",
       "12         defense      1\n",
       "13       commander      1\n",
       "14            been      1\n",
       "15         ability      1\n",
       "16  reconnaissance      1\n",
       "17             has      1\n",
       "18             air      1\n",
       "19            that      1\n",
       "20         nuclear      1\n",
       "21              to      1\n",
       "22        airborne      1\n",
       "23       secretary      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(set(example3))\n",
    "print([[x,example3.count(x)] for x in set(example3)])\n",
    "pd.DataFrame([[x,example3.count(x)] for x in set(example3)], columns = ['Word', 'Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1611\n"
     ]
    }
   ],
   "source": [
    "trainheadlines = []  # 这是一个list，是一个构造好的非常大的一个库，存储了每一列拼接完的所有的句子\n",
    "print(len(train.index))\n",
    "for row in range(0,len(train.index)):\n",
    "    trainheadlines.append(' '.join(str(x) for x in train.iloc[row,2:27]))  # 其实也就是先把每一行的所有的句子(Top1-Top25)拼接在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1611\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(1611, 31675)\n"
     ]
    }
   ],
   "source": [
    "print(len(trainheadlines))\n",
    "basicvectorizer = CountVectorizer()\n",
    "# 通用向量使用  CountVectorizer在一个类中实现了标记和计数，这个模型有许多参数，不过默认值已经非常合理\n",
    "basictrain = basicvectorizer.fit_transform(trainheadlines) # fit_transform是求出了有31675个不重复的单词\n",
    "print(type(basictrain))\n",
    "print(basictrain.shape)\n",
    "# 每一个数据都有31675列，是用来统计词频的，统计这31675个词每个词出现的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "basicmodel = LogisticRegression(solver = 'liblinear')\n",
    "basicmodel = basicmodel.fit(basictrain, train[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(378, 31675)\n",
      "<class 'numpy.ndarray'>\n",
      "(378,)\n",
      "378\n",
      "0.42592592592592593\n"
     ]
    }
   ],
   "source": [
    "testheadlines = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "print(len(testheadlines))\n",
    "basictest = basicvectorizer.transform(testheadlines)\n",
    "print(type(basictest))\n",
    "print(basictest.shape)\n",
    "predictions = basicmodel.predict(basictest)\n",
    "print(type(predictions))\n",
    "print(predictions.shape)\n",
    "print(len(predictions))\n",
    "accuracy1 = len(predictions[predictions == test[\"Label\"]]) / len(predictions)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>125</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>100</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>All</td>\n",
       "      <td>153</td>\n",
       "      <td>225</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1  All\n",
       "Actual                  \n",
       "0           61  125  186\n",
       "1           92  100  192\n",
       "All        153  225  378"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交叉表crosstab 可以按照指定的行和列统计分组频数，用起来非常方便\n",
    "# 交叉表是用于统计分组频率的特殊透视表\n",
    "# print(pd.crosstab(df['类别'],df['产地'],margins=True)) # 按类别分组，统计各个分组中产地的频数\n",
    "pd.crosstab(test[\"Label\"], predictions, rownames=[\"Actual\"], colnames=[\"Predicted\"], margins=True)  # margins=True这玩意就是求和的作用\n",
    "# 第一个参数是指定index，第二个参数是指定column  \n",
    "#0.42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "31675\n",
      "<class 'list'>\n",
      "31675\n",
      "   Coefficient    Word\n",
      "0    -0.080392      00\n",
      "1    -0.240865     000\n",
      "2     0.013129  000bpd\n",
      "3     0.004757   000ft\n",
      "4     0.006465  000new\n",
      "5    -0.048042    000s\n",
      "6     0.009336   000sq\n",
      "7    -0.005848     001\n",
      "8    -0.005132     004\n",
      "9    -0.011835    00am\n",
      "       Coefficient       Word\n",
      "19419     0.497924    nigeria\n",
      "25261     0.452526       self\n",
      "29286     0.428011         tv\n",
      "15998     0.425863      korea\n",
      "20135     0.425716   olympics\n",
      "15843     0.411636      kills\n",
      "26323     0.411267         so\n",
      "29256     0.394855       turn\n",
      "10874     0.388555      fears\n",
      "28274     0.384031  territory\n"
     ]
    }
   ],
   "source": [
    "basicwords = basicvectorizer.get_feature_names()\n",
    "print(type(basicwords))\n",
    "print(len(basicwords))\n",
    "basiccoeffs = basicmodel.coef_.tolist()[0]  # coef_表示当前model的一系列的权重参数\n",
    "print(type(basiccoeffs))\n",
    "print(len(basiccoeffs))\n",
    "coeffdf = pd.DataFrame({'Word' : basicwords, \n",
    "                        'Coefficient' : basiccoeffs})\n",
    "print(coeffdf.head(10))\n",
    "coeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])  # 以降序排列，Coefficient从高到低\n",
    "print(coeffdf.head(10)) # 对比一下，看的明白一些"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27299</td>\n",
       "      <td>-0.424441</td>\n",
       "      <td>students</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8478</td>\n",
       "      <td>-0.427079</td>\n",
       "      <td>did</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6683</td>\n",
       "      <td>-0.431925</td>\n",
       "      <td>congo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12818</td>\n",
       "      <td>-0.444069</td>\n",
       "      <td>hacking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7139</td>\n",
       "      <td>-0.448571</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16949</td>\n",
       "      <td>-0.463116</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3651</td>\n",
       "      <td>-0.470454</td>\n",
       "      <td>begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25433</td>\n",
       "      <td>-0.494555</td>\n",
       "      <td>sex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24754</td>\n",
       "      <td>-0.549725</td>\n",
       "      <td>sanctions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24542</td>\n",
       "      <td>-0.587794</td>\n",
       "      <td>run</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Coefficient       Word\n",
       "27299    -0.424441   students\n",
       "8478     -0.427079        did\n",
       "6683     -0.431925      congo\n",
       "12818    -0.444069    hacking\n",
       "7139     -0.448571    country\n",
       "16949    -0.463116        low\n",
       "3651     -0.470454      begin\n",
       "25433    -0.494555        sex\n",
       "24754    -0.549725  sanctions\n",
       "24542    -0.587794        run"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffdf.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedvectorizer = CountVectorizer(ngram_range=(2,2)) # 没指定参数，默认是一个单词一个单词进行分词\n",
    "# 通用向量使用 CountVectorizer在一个类中实现了标记和计数，这个模型有许多参数，不过默认值已经非常合理\n",
    "# 在这里指定参数(2,2)是两个单词两个单词进行分的了\n",
    "advancedtrain = advancedvectorizer.fit_transform(trainheadlines)\n",
    "# fit_transform是求出了有366721对不重复的相邻两个单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 366721)\n"
     ]
    }
   ],
   "source": [
    "print(advancedtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedmodel = LogisticRegression(solver = 'liblinear')\n",
    "advancedmodel = advancedmodel.fit(advancedtrain, train[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378, 27)\n",
      "378\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(378, 366721)\n",
      "<class 'numpy.ndarray'>\n",
      "(378,)\n",
      "378\n",
      "0.5634920634920635\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "testheadlines = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "print(len(testheadlines))\n",
    "advancedtest = advancedvectorizer.transform(testheadlines)\n",
    "print(type(advancedtest))\n",
    "print(advancedtest.shape)\n",
    "advpredictions = advancedmodel.predict(advancedtest)\n",
    "print(type(advpredictions))\n",
    "print(advpredictions.shape)\n",
    "print(len(advpredictions))\n",
    "accuracy2 = len(advpredictions[advpredictions == test[\"Label\"]]) / len(advpredictions)\n",
    "print(accuracy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>120</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>147</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>All</td>\n",
       "      <td>111</td>\n",
       "      <td>267</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1  All\n",
       "Actual                  \n",
       "0           66  120  186\n",
       "1           45  147  192\n",
       "All        111  267  378"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test[\"Label\"], advpredictions, rownames=[\"Actual\"], colnames=[\"Predicted\"],  margins=True)\n",
    "#.57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>272047</td>\n",
       "      <td>0.286533</td>\n",
       "      <td>right to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24710</td>\n",
       "      <td>0.275274</td>\n",
       "      <td>and other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285392</td>\n",
       "      <td>0.274698</td>\n",
       "      <td>set to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>316194</td>\n",
       "      <td>0.262873</td>\n",
       "      <td>the first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157511</td>\n",
       "      <td>0.227943</td>\n",
       "      <td>in china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159522</td>\n",
       "      <td>0.224184</td>\n",
       "      <td>in south</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125870</td>\n",
       "      <td>0.219130</td>\n",
       "      <td>found in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124411</td>\n",
       "      <td>0.216726</td>\n",
       "      <td>forced to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173246</td>\n",
       "      <td>0.211137</td>\n",
       "      <td>it has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>322590</td>\n",
       "      <td>0.209239</td>\n",
       "      <td>this is</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Coefficient      Words\n",
       "272047     0.286533   right to\n",
       "24710      0.275274  and other\n",
       "285392     0.274698     set to\n",
       "316194     0.262873  the first\n",
       "157511     0.227943   in china\n",
       "159522     0.224184   in south\n",
       "125870     0.219130   found in\n",
       "124411     0.216726  forced to\n",
       "173246     0.211137     it has\n",
       "322590     0.209239    this is"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advwords = advancedvectorizer.get_feature_names()\n",
    "advcoeffs = advancedmodel.coef_.tolist()[0]   # coef_表示当前model的一系列的权重参数\n",
    "advcoeffdf = pd.DataFrame({'Words' : advwords, \n",
    "                        'Coefficient' : advcoeffs})\n",
    "advcoeffdf = advcoeffdf.sort_values(['Coefficient', 'Words'], ascending=[0, 1])  # 以降序排列，Coefficient从高到低\n",
    "advcoeffdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>326846</td>\n",
       "      <td>-0.198495</td>\n",
       "      <td>to help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118707</td>\n",
       "      <td>-0.201654</td>\n",
       "      <td>fire on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155038</td>\n",
       "      <td>-0.209702</td>\n",
       "      <td>if he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242528</td>\n",
       "      <td>-0.211303</td>\n",
       "      <td>people are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31669</td>\n",
       "      <td>-0.213362</td>\n",
       "      <td>around the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321333</td>\n",
       "      <td>-0.215699</td>\n",
       "      <td>there is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>327113</td>\n",
       "      <td>-0.221812</td>\n",
       "      <td>to kill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340714</td>\n",
       "      <td>-0.226289</td>\n",
       "      <td>up in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>358917</td>\n",
       "      <td>-0.227516</td>\n",
       "      <td>with iran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315485</td>\n",
       "      <td>-0.331153</td>\n",
       "      <td>the country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Coefficient        Words\n",
       "326846    -0.198495      to help\n",
       "118707    -0.201654      fire on\n",
       "155038    -0.209702        if he\n",
       "242528    -0.211303   people are\n",
       "31669     -0.213362   around the\n",
       "321333    -0.215699     there is\n",
       "327113    -0.221812      to kill\n",
       "340714    -0.226289        up in\n",
       "358917    -0.227516    with iran\n",
       "315485    -0.331153  the country"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advcoeffdf.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedvectorizer = CountVectorizer(ngram_range=(3,3)) # 没指定参数，默认是一个单词一个单词进行分词\n",
    "# 通用向量使用 CountVectorizer在一个类中实现了标记和计数，这个模型有许多参数，不过默认值已经非常合理\n",
    "# 在这里指定参数(3,3)是三个单词三个单词进行分的了\n",
    "advancedtrain = advancedvectorizer.fit_transform(trainheadlines)\n",
    "# fit_transform是求出了有611140对不重复的相邻三个单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 611140)\n"
     ]
    }
   ],
   "source": [
    "print(advancedtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "advancedmodel = LogisticRegression(solver = 'liblinear')\n",
    "advancedmodel = advancedmodel.fit(advancedtrain, train[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378, 27)\n",
      "378\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(378, 611140)\n",
      "<class 'numpy.ndarray'>\n",
      "(378,)\n",
      "378\n",
      "0.5026455026455027\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "testheadlines = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\n",
    "print(len(testheadlines))\n",
    "advancedtest = advancedvectorizer.transform(testheadlines)\n",
    "print(type(advancedtest))\n",
    "print(advancedtest.shape)\n",
    "advpredictions = advancedmodel.predict(advancedtest)\n",
    "print(type(advpredictions))\n",
    "print(advpredictions.shape)\n",
    "print(len(advpredictions))\n",
    "accuracy3 = len(advpredictions[advpredictions == test[\"Label\"]]) / len(advpredictions)\n",
    "print(accuracy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>547048</td>\n",
       "      <td>0.166334</td>\n",
       "      <td>to the us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>517059</td>\n",
       "      <td>0.166060</td>\n",
       "      <td>the right to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>346406</td>\n",
       "      <td>0.159357</td>\n",
       "      <td>nobel peace prize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>509309</td>\n",
       "      <td>0.139584</td>\n",
       "      <td>the first time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240485</td>\n",
       "      <td>0.127362</td>\n",
       "      <td>human rights watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>258131</td>\n",
       "      <td>0.119392</td>\n",
       "      <td>in west bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183395</td>\n",
       "      <td>0.118138</td>\n",
       "      <td>first time in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225498</td>\n",
       "      <td>0.112187</td>\n",
       "      <td>have been killed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365956</td>\n",
       "      <td>0.110323</td>\n",
       "      <td>of the country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>527430</td>\n",
       "      <td>0.108360</td>\n",
       "      <td>this is the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Coefficient               Words\n",
       "547048     0.166334           to the us\n",
       "517059     0.166060        the right to\n",
       "346406     0.159357   nobel peace prize\n",
       "509309     0.139584      the first time\n",
       "240485     0.127362  human rights watch\n",
       "258131     0.119392        in west bank\n",
       "183395     0.118138       first time in\n",
       "225498     0.112187    have been killed\n",
       "365956     0.110323      of the country\n",
       "527430     0.108360         this is the"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advwords = advancedvectorizer.get_feature_names()\n",
    "advcoeffs = advancedmodel.coef_.tolist()[0]   # coef_表示当前model的一系列的权重参数\n",
    "advcoeffdf = pd.DataFrame({'Words' : advwords, \n",
    "                        'Coefficient' : advcoeffs})\n",
    "advcoeffdf = advcoeffdf.sort_values(['Coefficient', 'Words'], ascending=[0, 1])  # 以降序排列，Coefficient从高到低\n",
    "advcoeffdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>258129</td>\n",
       "      <td>-0.107452</td>\n",
       "      <td>in west africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>547434</td>\n",
       "      <td>-0.108206</td>\n",
       "      <td>to try to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398829</td>\n",
       "      <td>-0.109387</td>\n",
       "      <td>phone hacking scandal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>524610</td>\n",
       "      <td>-0.119903</td>\n",
       "      <td>there is no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>447327</td>\n",
       "      <td>-0.124095</td>\n",
       "      <td>said to be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359681</td>\n",
       "      <td>-0.125929</td>\n",
       "      <td>of human rights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222471</td>\n",
       "      <td>-0.134566</td>\n",
       "      <td>has been arrested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>378538</td>\n",
       "      <td>-0.138594</td>\n",
       "      <td>one of the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51915</td>\n",
       "      <td>-0.188984</td>\n",
       "      <td>around the world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256482</td>\n",
       "      <td>-0.211493</td>\n",
       "      <td>in the country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Coefficient                  Words\n",
       "258129    -0.107452         in west africa\n",
       "547434    -0.108206              to try to\n",
       "398829    -0.109387  phone hacking scandal\n",
       "524610    -0.119903            there is no\n",
       "447327    -0.124095             said to be\n",
       "359681    -0.125929        of human rights\n",
       "222471    -0.134566      has been arrested\n",
       "378538    -0.138594             one of the\n",
       "51915     -0.188984       around the world\n",
       "256482    -0.211493         in the country"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advcoeffdf.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
